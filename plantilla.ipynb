{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e262b5ef",
   "metadata": {},
   "source": [
    "Plantilla de Notebook para K-Means Clustering\n",
    "1. Configuración e Importación de Librerías\n",
    "Esta sección establece el entorno y carga las librerías necesarias para la manipulación de datos, visualización y el algoritmo K-Means.\n",
    "## Importación de librerías esenciales\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler # Aunque las fuentes usan Min-Max, StandardScaler es una alternativa común.\n",
    "\n",
    "from sklearn.decomposition import PCA # Utilizado en algunos contextos de ML, mencionado en las librerías importadas.\n",
    "\n",
    "\n",
    "\n",
    "Citas:\n",
    "2. Carga y Exploración Inicial de Datos\n",
    "Se carga el conjunto de datos (bdclientes.csv) y se realiza una exploración inicial para comprender su estructura y contenido.\n",
    "## Carga de datos\n",
    "df = pd.read_csv('bdclientes.csv')\n",
    "\n",
    "## Exploración de las primeras filas\n",
    "print(df.head())\n",
    "## Columnas observadas en el ejemplo: IDCLIENTE, Genero, Tiene_auto, Tiene_propiedad, Num_hijos, Ingreso_anual, Categoria_ingresos, Estudios, Estado_civil [1]\n",
    "\n",
    "# Exploración estadística (ejemplo basado en las fuentes)\n",
    "print(df.describe())\n",
    "## Muestra estadísticas para variables numéricas como IDCLIENTE, Tiene_auto, Tiene_propiedad, Num_hijos, Ingreso_anual [3, 4]\n",
    "Citas:\n",
    "3. Preparación y Limpieza de Datos\n",
    "Esta fase es crucial para asegurar que las variables estén en un formato adecuado para el algoritmo K-Means (numérico y escalado).\n",
    "3.1. Limpieza y Unificación de Variables Categóricas\n",
    "Se unifican categorías y se realiza una limpieza inicial.\n",
    "## Unificación de 'Estado_civil' (Civil marriage se combina con Married)\n",
    "df.Estado_civil = df.Estado_civil.replace({'Civil marriage' : 'Married'})\n",
    "## Se observa que el conteo de 'Estado_civil' cambia: Married (261593), Single/not married (42730), Separated (20973), Widow (15177) [5, 6]\n",
    "Citas:\n",
    "3.2. Eliminación de Variables Innecesarias\n",
    "Se eliminan variables que no se usarán para el clustering o que son identificadores.\n",
    "## Eliminación de la variable 'Estudios' para efectos del ejercicio [6]\n",
    "df = df.drop('Estudios', axis=1)\n",
    "\n",
    "## Eliminación de la columna de identificación 'IDCLIENTE' [7]\n",
    "df_dummies =df_dummies.drop('IDCLIENTE', axis=1) # Asumiendo que esta operación se realiza sobre el DataFrame preparado.\n",
    "Citas:\n",
    "3.3. Codificación de Variables Categóricas\n",
    "Se convierten las variables categóricas a formato numérico (codificación binaria y One-Hot Encoding).\n",
    "# Codificación binaria de 'Genero' (F: 0, M: 1) [6]\n",
    "df.Genero = df.Genero.replace({'F' : 0, 'M' : 1})\n",
    "\n",
    "## Codificación One-Hot para variables restantes\n",
    "df_dummies = pd.get_dummies(df, columns=['Categoria_ingresos', 'Estado_civil'])\n",
    "## Esto crea nuevas columnas dummy para cada categoría [6, 7]\n",
    "\n",
    "## Convertir valores booleanos (True/False) resultantes de get_dummies a 1 y 0 [8, 9]\n",
    "df_dummies = df_dummies.replace({True: 1, False: 0})\n",
    "Citas:\n",
    "3.4. Normalización de Datos\n",
    "Se aplica la Normalización Min-Max para asegurar que ninguna variable domine el análisis debido a su escala.\n",
    "## Manejar posibles valores nulos antes de la normalización\n",
    "df_dummies.dropna(inplace=True)\n",
    "\n",
    "## Normalización Min-Max\n",
    "df_norm = (df_dummies - df_dummies.min()) / (df_dummies.max() - df_dummies.min())\n",
    "## df_norm ahora contiene los datos escalados entre 0 y 1 [10]\n",
    "Citas:\n",
    "4. Determinación del Número Óptimo de Clusters (Método del Codo)\n",
    "Se utiliza el Método del Codo (Elbow Method) analizando la Suma de Cuadrados Dentro del Cluster (WCSS) para encontrar el número $k$ ideal.\n",
    "wcs =[]\n",
    "\n",
    "## Iterar de 1 a 15 clusters\n",
    "for i in range(1,16):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=0, n_init='auto') # n_init='auto' para versiones recientes de sklearn\n",
    "    kmeans.fit(df_norm)\n",
    "    wcs.append(kmeans.inertia_)\n",
    "\n",
    "## Visualización del Método del Codo\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.grid()\n",
    "plt.plot(range(1,16), wcs, marker='+', color='blue')\n",
    "plt.xlabel('Número de clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.title('Método del codo para determinar el número óptimo de clusters')\n",
    "plt.show()\n",
    "## Basado en el análisis gráfico, las fuentes sugieren que 6 clusters es el número óptimo [11, 12]\n",
    "Citas:\n",
    "5. Modelado K-Means y Cálculo de Centroides\n",
    "Se aplica el algoritmo K-Means utilizando el número óptimo de clusters (en este caso, $k=6$) y se capturan los centroides.\n",
    "## Aplicación del algoritmo K-Means con k=6\n",
    "num_clusters = 6\n",
    "clustering = KMeans(n_clusters=num_clusters, max_iter=300, random_state=0, n_init='auto')\n",
    "clustering.fit(df_norm)\n",
    "\n",
    "## Capturar los centroides del modelo\n",
    "center = clustering.cluster_centers_\n",
    "## Los centroides están en formato normalizado [12]\n",
    "Citas:\n",
    "6. Interpretación de Resultados (Desnormalización)\n",
    "Para interpretar los perfiles de los clientes, los centroides deben ser llevados a su escala original.\n",
    "6.1. Función de Desnormalización\n",
    "Se define una función que revierte la normalización Min-Max.\n",
    "def desnormalizar(df, columns_name_list, num_clusters):\n",
    "    \"\"\"Revierte la normalización Min-Max aplicada a los centroides.\"\"\"\n",
    "    data_desnorm = [[] for _ in range(num_clusters)]\n",
    "    for i in range(num_clusters):\n",
    "        for j in range(len(columns_name_list)):\n",
    "            # Fórmula de desnormalización: Min + Centroide_Normalizado * (Max - Min)\n",
    "            data_desnorm[i].append(df[columns_name_list[j]].min() + center[i][j]*(df[columns_name_list[j]].max() - df[columns_name_list[j]].min()))\n",
    "    return np.asarray(data_desnorm)\n",
    "Citas:\n",
    "6.2. Aplicación y Organización de Centroides\n",
    "Se aplica la desnormalización y se organizan los resultados en un DataFrame legible.\n",
    "## Nombres de las columnas originales\n",
    "columns_name = list(df_norm.columns.values)\n",
    "\n",
    "## Desnormalizar los centroides\n",
    "df_desnorm = desnormalizar(df_dummies, columns_name, num_clusters)\n",
    "\n",
    "## Organizar los resultados en un DataFrame con nombres de clusters\n",
    "names = []\n",
    "for i in range(num_clusters):\n",
    "    names.append('Cluster_{}' .format(i+1))\n",
    "\n",
    "df_centroides = pd.DataFrame(df_desnorm.transpose(), columns=names).abs().round(3)\n",
    "columns_names_series = pd.Series(df_norm.columns.values)\n",
    "df_centroides.set_index([columns_names_series], inplace=True)\n",
    "\n",
    "## Visualizar los centroides desnormalizados\n",
    "df_centroides"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
